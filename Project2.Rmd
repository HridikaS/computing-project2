---
title: "Project2"
output: html_document
date: "2024-09-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(here)
library(dplyr)
library(tidyverse)
library(tidytuesdayR)
library(readr)
```

## Part 1: Fun with Functions

### Part 1A: Exponential transformation

Of course, we cannot compute an infinite series by the end of this term and so we must truncate it at a certain point in the series. The truncated sum of terms represents an approximation to the true exponential, but the approximation may be usable.

Write a function that computes the exponential of a number using the truncated series expansion. The function should take two arguments:

- x: the number to be exponentiated
- k: the number of terms to be used in the series expansion beyond the constant 1. The value of k is always greater than or equal to 1. 

Assume:
- the input value x will always be a single number.
- You can assume that the value k will always be an integer greater than or equal to 1
- Do not use the exp() function in R.
- The factorial() function can be used to compute factorials.

```{r}
Exp <- function(x, k) {
      k_total <- 0
    while (k >= 1) {
      k_value <- ((x^k)/factorial(k))
      k_total <- k_total + k_value
      k <- k-1
}
    print(1 + k_total)
}

Exp(2,4) # Example where x = 2 and k = 4
```

### Part 1B: Sample mean and sample standard deviation

Next, write two functions called sample_mean() and sample_sd() that takes as input a vector of data of length 
N and calculates the sample average and sample standard deviation for the set of 
N observations.

```{r}
sample_mean <- function(x) {
  mean <- sum(x)/length(x)
  return(mean)
}

sample_sd <- function(x) {
     mean <- sum(x)/length(x)
     sq_diff_mean <- (x - mean)^2
     sd <- sqrt(sum(sq_diff_mean)/(length(x)-1))
     return(sd)
}

# Example data
maacs <- read_csv(here("data", "maacs_sim copy.csv"))
pm25_v <- maacs$pm25 # Create vector of pm25

sample_mean(pm25_v) # Mean calculation
sample_sd(pm25_v) # Standard Deviation calculation

```

### Part 1C: Confidence intervals

Next, write a function called calculate_CI()

```{r}
calculate_CI <- function(x, conf = 0.95) {
  mean <- sum(x)/length(x)
    sq_diff_mean <- (x - mean)^2
    sd <- sqrt(sum(sq_diff_mean)/(length(x)-1))
  se <- sd/sqrt(length(x))
    alpha <- 1 - conf
    degrees_freedom <- length(x) - 1
  t_score <- qt(p = alpha/2, df = degrees_freedom, lower.tail = FALSE)
  ci <- c((mean - t_score*se), (mean + t_score*se))
  return(ci)
}

# Example confidence interval calculations
calculate_CI(pm25_v, conf = 0.975)
calculate_CI(pm25_v, conf = 0.90)
```

## Part 2: Wrangling data

### Data

```{r}
rainfall <- readRDS(here("data", "tuesdata_rainfall.RDS"))
temperature <- readRDS(here("data", "tuesdata_temperature.RDS"))
```

### Tasks

1. Start with rainfall dataset and drop any rows with NAs

2. Create a new column titled date that combines the columns year, month, day into one column separated by “-”. (e.g. “2020-01-01”). This column should not be a character, but should be recognized as a date. (Hint: check out the ymd() function in lubridate R package). You will also want to add a column that just keeps the year.

3. Using the city_name column, convert the city names (character strings) to all upper case.

4. Join this wrangled rainfall dataset with the temperature dataset such that it includes only observations that are in both data frames. (Hint: there are two keys that you will need to join the two datasets together). (Hint: If all has gone well thus far, you should have a dataset with 83,964 rows and 13 columns).

```{r}
rainfall <- rainfall %>% ## 1. drop na values
  drop_na() 

library(lubridate)
rainfall <- rainfall %>% ## convert day and month to numeric vectors
  mutate(day = as.numeric(day), month = as.numeric(month))

rainfall <- rainfall %>% ## 2. create date variable, drop month and day
  mutate("date" = make_date(year, month, day)) %>%
  select(-c("month", 'day'))

## rainfall <- rainfall %>% ## make year variable
  ## mutate(date_year = lubridate::ymd(year, truncated = 2L))

rainfall <- rainfall %>% ## 3. mutate city_name
  mutate(city_name = toupper(city_name))

df <- inner_join(rainfall, temperature, by = c("city_name", "date")) # 4. combine data frames
```

## Part 3: Data visualization

In this part, we will practice our ggplot2 plotting skills within the tidyverse starting with our wrangled df data from Part 2. For full credit in this part (and for all plots that you make), your plots should include:

- An overall title for the plot and a subtitle summarizing key trends that you found. Also include a caption in the   figure.
- There should be an informative x-axis and y-axis label.

Consider playing around with the theme() function to make the figure shine, including playing with background      colors, font, etc.

### Part 3A: Plotting temperature data over time

Use the functions in ggplot2 package to make a line plot of the max and min temperature (y-axis) over time (x-axis) for each city in our wrangled data from Part 2. You should only consider years 2014 and onwards. For full credit, your plot should include:

- For a given city, the min and max temperature should both appear on the plot, but they should be two different colors.
- Use a facet function to facet by city_name to show all cities in one figure.

```{r}
gg1 <- df %>%
  filter(year >= 2014) %>%  
  group_by(city_name, year) %>%
  summarize(temp_min = min(temperature), temp_max = max(temperature)) %>%
  pivot_longer(cols = starts_with("temp_"), names_to = "min_max", values_to = "range") %>%
    ggplot(aes(x = year, y = range, color = min_max)) + 
    geom_point() +  
    geom_line() + 
    facet_wrap(~city_name)


gg1 <- gg1 + labs(
        title = "Minimum and Maximum Temperature in Five Australian Cities from 2014-2019",
        subtitle = "Melbourne and Perth see variation in maximum temperatures from 2014-2019",
        x = "Year",
        y = "Temperature",
        caption = "Data source: TidyTuesday"
    )
print(gg1)
```

### Part 3B: Plotting rainfall over time

Here we want to explore the distribution of rainfall (log scale) with histograms for a given city (indicated by the city_name column) for a given year (indicated by the year column) so we can make some exploratory plots of the data.

The following code plots the data from one city (city_name == "PERTH") in a given year (year == 2000).

```{r}
df %>%
    filter(city_name == "PERTH", year == 2000) %>%
    ggplot(aes(log(rainfall))) +
    geom_histogram()
```

The aim here is to design and implement a function that can be re-used to visualize all of the data in this dataset. There are 2 aspects that may vary in the dataset: The city_name and the year. Note that not all combinations of city_name and year have measurements.

Your function should take as input two arguments city_name and year.

Given the input from the user, your function should return a single histogram for that input. Furthermore, the data should be readable on that plot so that it is in fact useful. It should be possible visualize the entire dataset with your function (through repeated calls to your function).

If the user enters an input that does not exist in the dataset, your function should catch that and report an error (via the stop() function).

```{r, error=TRUE}
ggplot_function <- function(city, time) {
  if (!(city %in% df$city_name) || # Error message for invalid inputs 
      !(time %in% df$year)) { 
    stop("Error: Invalid input. Please check the input parameters before trying again.")
  }
  df %>%
    filter(city_name == !!city, year == !!time) %>%  # Filter data based on the city and year
    ggplot(aes(log(rainfall))) +  # Plot histogram for the log of rainfall
    geom_histogram() +  
    labs(title = paste("Rainfall in", city, "for the year", time),
         subtitle = paste("Variation in distribution of rainfall in", city, "in", time),
         x = "Log of Rainfall",
         y = "Frequency",
         caption = "Data source: TidyTuesday")
}

ggplot_function("PERTH", 2000) # Call

ggplot_function("NEW YORK", 2000) # Error
```

For this section, write a short description of how you chose to design your function and why.

*I wrote a function with two arguments, city and time. The first seciton of code within the function checks to see if the city exists wtihin the city_name column in the dataframe (df) and whether the time exists in the year column of the dataframe. If not, the function yields a stop error message to check the input parameters. If these two conditions are met, the function filters the dataframe by that specific year and city. It then creates a histogram of the log(rainfall) in that year against the frequency of times it occurred. The function includes a modifiable title based on the city and time inputs when called.*

## Part 4: Apply functions and plot

### Part 4A: Tasks

In this part, we will apply the functions we wrote in Part 1 to our rainfall data starting with our wrangled df data from Part 2.

1. First, filter for only years including 2014 and onwards.

```{r}
df2014 <- df %>%
  filter(year >= 2014)
```

2. For a given city and for a given year, calculate the sample mean (using your function sample_mean()), the sample standard deviation (using your function sample_sd()), and a 95% confidence interval for the average rainfall (using your function calculate_CI()). Specifically, you should add two columns in this summarized dataset: a column titled lower_bound and a column titled upper_bound containing the lower and upper bounds for you CI that you calculated (using your function calculate_CI()).

3. Call this summarized dataset rain_df.

```{r}

five_cities <- unique(df2014$city_name)
six_years <- unique(df2014$year)

rain_df <- data.frame(
  city = character(),
  year = integer(),
  rain_mean = numeric(),
  rain_sd = numeric(),
  lower_bound = numeric(),
  upper_bound = numeric(),
  stringsAsFactors = FALSE
)

for(city in seq_along(five_cities)) {
  for(time in seq_along(six_years)) {
    filtered_df2014 <- df2014 %>%
      filter(city_name == five_cities[city], year == six_years[time])
        rain_mean <- sample_mean(filtered_df2014$rainfall)
        rain_sd <- sample_sd(filtered_df2014$rainfall)
        rain_ci <- calculate_CI(filtered_df2014$rainfall)
          lower_bound <- rain_ci[1]
          upper_bound <- rain_ci[2]
      rain_df <- rbind(rain_df, data.frame(
                       city = five_cities[city],
                       year = six_years[time],
                       rain_mean = rain_mean,
                       rain_sd = rain_sd,
                       lower_bound = lower_bound,
                       upper_bound = upper_bound,
                       stringsAsFactors = FALSE))
    }
}
```

### Part 4B: Tasks

Using the rain_df, plots the estimates of mean rainfall and the 95% confidence intervals on the same plot. There should be a separate faceted plot for each city. Think about using ggplot() with both geom_point() (and geom_line() to connect the points) for the means and geom_errorbar() for the lower and upper bounds of the confidence interval. Check https://r-graphics.org/recipe-annotate-error-bar and or the official documentation https://ggplot2.tidyverse.org/reference/geom_linerange.html for examples of how to use geom_errorbar().
```{r}
gg2 <- rain_df %>%
    ggplot(aes(year, rain_mean)) + 
    geom_point() +
    geom_line() + 
    geom_errorbar(aes(ymin = lower_bound, ymax = upper_bound)) +
    facet_wrap(~city) +
    labs(
      x = "Year",
      y = "Average Amount of Rainfall (mm)",
      title = "Average Amound of Rainfall in 5 Australian Cities 2014-2019",
      subtitle = "Brisbane, Perth, and Melbourne see greater variation in average rainfall from 2014-2019",
      caption = "Data source: TidyTuesday"
    )

print(gg2)
```

